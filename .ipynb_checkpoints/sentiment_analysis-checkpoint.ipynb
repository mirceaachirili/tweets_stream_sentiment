{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4fb5efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "\n",
    "import psycopg2 \n",
    "import credentials\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd0aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "conn = psycopg2.connect(database='TwitterDB', user=credentials.pg_user, password=credentials.pg_pass)\n",
    "\n",
    "# Open a cursor to perform database operations\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "950d19b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>datetime</th>\n",
       "      <th>user_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1416509325992996867</td>\n",
       "      <td>507812340</td>\n",
       "      <td>@suchHODL @elonmusk @Tesla Could we actually g...</td>\n",
       "      <td>2021-07-17 21:25:15</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1416509527634157573</td>\n",
       "      <td>1414385846653005826</td>\n",
       "      <td>@billycrammer @Tesla @elonmusk it's real cool</td>\n",
       "      <td>2021-07-17 21:26:03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1416509536974905346</td>\n",
       "      <td>1226350189</td>\n",
       "      <td>Welcome Tesla to the continuous revenue stream...</td>\n",
       "      <td>2021-07-17 21:26:05</td>\n",
       "      <td>Hubbard, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1416509550996295681</td>\n",
       "      <td>914412950</td>\n",
       "      <td>We just received our \"other Tesla,\" e-converte...</td>\n",
       "      <td>2021-07-17 21:26:09</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1416509554133716993</td>\n",
       "      <td>811882963</td>\n",
       "      <td>@elonmusk day 50: what about that Tesla now ?</td>\n",
       "      <td>2021-07-17 21:26:09</td>\n",
       "      <td>Chicago, IL - kashmiri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id              user_id  \\\n",
       "0  1416509325992996867            507812340   \n",
       "1  1416509527634157573  1414385846653005826   \n",
       "2  1416509536974905346           1226350189   \n",
       "3  1416509550996295681            914412950   \n",
       "4  1416509554133716993            811882963   \n",
       "\n",
       "                                               tweet            datetime  \\\n",
       "0  @suchHODL @elonmusk @Tesla Could we actually g... 2021-07-17 21:25:15   \n",
       "1      @billycrammer @Tesla @elonmusk it's real cool 2021-07-17 21:26:03   \n",
       "2  Welcome Tesla to the continuous revenue stream... 2021-07-17 21:26:05   \n",
       "3  We just received our \"other Tesla,\" e-converte... 2021-07-17 21:26:09   \n",
       "4      @elonmusk day 50: what about that Tesla now ? 2021-07-17 21:26:09   \n",
       "\n",
       "            user_location  \n",
       "0                      51  \n",
       "1                    None  \n",
       "2             Hubbard, OH  \n",
       "3       San Francisco, CA  \n",
       "4  Chicago, IL - kashmiri  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SQL query for accessing table data\n",
    "query = '''\n",
    "    SELECT t.*, tu.user_location FROM tweets AS t\n",
    "    LEFT JOIN twitter_user AS tu ON tu.user_id = t.user_id;\n",
    "'''\n",
    "\n",
    "# Read database table as Pandas Dataframe\n",
    "tweets = pd.read_sql(query, con=conn)\n",
    "\n",
    "# Preview dataframe\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa602312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21357 entries, 0 to 21356\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   tweet_id       21357 non-null  int64         \n",
      " 1   user_id        21357 non-null  int64         \n",
      " 2   tweet          21357 non-null  object        \n",
      " 3   datetime       21357 non-null  datetime64[ns]\n",
      " 4   user_location  14144 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(2)\n",
      "memory usage: 834.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# View dataframe dtypes\n",
    "\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "650c1152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date&time: 2021-10-26 16:02:45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>datetime</th>\n",
       "      <th>user_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tweet_id, user_id, tweet, datetime, user_location]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in tweets created in the last hour\n",
    "\n",
    "import datetime\n",
    "\n",
    "time_now = datetime.datetime.utcnow()\n",
    "time_before = datetime.timedelta(hours=1, minutes=0)\n",
    "time_interval = time_now - time_before\n",
    "\n",
    "\n",
    "query = '''\n",
    "    SELECT t.*, tu.user_location FROM tweets AS t\n",
    "    LEFT JOIN twitter_user AS tu ON tu.user_id = t.user_id\n",
    "    WHERE t.datetime >= '{}';\n",
    "        '''.format(time_interval)\n",
    "\n",
    "print('Current date&time:', time_now.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "df = pd.read_sql(query, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5acae216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis using TextBlob library\n",
    "\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    # Clean text for TextBlob\n",
    "    return ' '.join(re.sub(r'''(@[A-Za-z0-9_]+)|     # Remove mentions that start with @\n",
    "                                ([^0-9A-Za-z \\t])    # Remove non-alphanumeric (except space and tab) characters\n",
    "                                |(\\w+:\\/\\/\\S+)''',   # Remove web links\n",
    "                                \" \", tweet).split())\n",
    "    \n",
    "def analyze_polarity(tweet):\n",
    "    '''\n",
    "    Analyze polarity. Returns 1 for positive, 0 for neutral and -1 for negative.\n",
    "    '''\n",
    "    analysis = TextBlob(clean_tweet(tweet))\n",
    "\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 1\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def analyze_subjectivity(tweet):\n",
    "    '''\n",
    "    Subjectivity analizer. Returns 1 if tweet is subjective or 0 if tweet is objective\n",
    "    '''\n",
    "    analysis = TextBlob(clean_tweet(tweet))\n",
    "    if analysis.sentiment.subjectivity >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1740aff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>datetime</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tweet, datetime, polarity]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe containing the polarity and subjectivity of tweets\n",
    "\n",
    "tweets = df.loc[:, ['tweet', 'datetime']]\n",
    "tweets['polarity'] = tweets['tweet'].apply(analyze_polarity)\n",
    "\n",
    "# Preview dataframe\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c074c75",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ce9c1ddebca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Preview sentiment for first two tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Full tweet:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Polarity:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    887\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1450\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1451\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1359\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m             \u001b[0;31m# a tuple should already have been caught by this point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# Preview sentiment for first two tweets\n",
    "for i in range(2):\n",
    "    print('Full tweet:', tweets.iloc[i,0])\n",
    "    print('Polarity:', tweets.iloc[i, 2], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341e7adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group tweets count by time and polarity\n",
    "tweets_grouped = tweets.groupby([pd.Grouper(key='datetime', freq='1min'), 'polarity']) \\\n",
    "                        .count().unstack(fill_value=0).stack().reset_index()\n",
    "tweets_grouped = tweets_grouped.rename(columns={\n",
    "    'datetime': 'Time in UTC',\n",
    "    'tweet': 'Number of mentions'\n",
    "})\n",
    "tweets_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07211ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare time series data\n",
    "time_series = tweets_grouped['Time in UTC'][tweets_grouped['polarity'] == 0].reset_index(drop=True)\n",
    "\n",
    "negative_polarity = tweets_grouped['Number of mentions'][tweets_grouped['polarity'] == -1].reset_index(drop=True)\n",
    "neutral_polarity = tweets_grouped['Number of mentions'][tweets_grouped['polarity'] == 0].reset_index(drop=True)\n",
    "positive_polarity = tweets_grouped['Number of mentions'][tweets_grouped['polarity'] == 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c04fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tweets sentiment analysis\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=time_series, y=negative_polarity, mode='lines+markers', name='negative'))\n",
    "fig.add_trace(go.Scatter(x=time_series, y=neutral_polarity, mode='lines+markers', name='neutral'))\n",
    "fig.add_trace(go.Scatter(x=time_series, y=positive_polarity, mode='lines+markers', name='positive'))\n",
    "\n",
    "fig.update_layout(title={'text': 'Real Time Tweets Sentiment Tracker',\n",
    "                        'y':0.9,\n",
    "                        'x':0.5,\n",
    "                        'xanchor': 'center',\n",
    "                        'yanchor': 'top'},\n",
    "                 xaxis_title='Time', yaxis_title='Number of mentions')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb91917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process tweets for words frequency distribution\n",
    "\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    \"\"\"Process tweet function.\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        tweets_clean: a list of words containing the processed tweet\n",
    "\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtags (only the hashtag symbol)\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    # remove punctuation\n",
    "    tweet = re.sub('[^A-Za-z0-9]+', ' ', tweet)\n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if word not in stopwords_english:  # remove stopwords\n",
    "            # stem and add word to tweets_clean list\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91772994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create frequency distribution\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "b = process_tweet(' '.join(tweets['tweet']))\n",
    "freq_b = FreqDist(b)\n",
    "\n",
    "# Preview distribution\n",
    "freq_b.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top 10 most common words\n",
    "top_words = pd.DataFrame(freq_b.most_common(10),\n",
    "                        columns=['Word', 'Frequency']).drop(0).reset_index(drop=True)\n",
    "top_words\n",
    "\n",
    "fig1 = px.bar(top_words, x='Word', y='Frequency')\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0067147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# US States and abbreviations for choropleth map\n",
    "\n",
    "us_states = ['Alabama', 'AL', 'Alaska', 'AK', 'American Samoa', 'AS', 'Arizona', 'AZ', 'Arkansas', 'AR', 'California', \n",
    "          'CA', 'Colorado', 'CO', 'Connecticut', 'CT', 'Delaware', 'DE', 'District of Columbia', 'DC', \n",
    "          'Federated States of Micronesia', 'FM', 'Florida', 'FL', 'Georgia', 'GA', 'Guam', 'GU', 'Hawaii', 'HI', \n",
    "          'Idaho', 'ID', 'Illinois', 'IL', 'Indiana', 'IN', 'Iowa', 'IA', 'Kansas', 'KS', 'Kentucky', 'KY', \n",
    "          'Louisiana', 'LA', 'Maine', 'ME', 'Marshall Islands', 'MH', 'Maryland', 'MD', 'Massachusetts', 'MA', \n",
    "          'Michigan', 'MI', 'Minnesota', 'MN', 'Mississippi', 'MS', 'Missouri', 'MO', 'Montana', 'MT', \n",
    "          'Nebraska', 'NE', 'Nevada', 'NV', 'New Hampshire', 'NH', 'New Jersey', 'NJ', 'New Mexico', 'NM', \n",
    "          'New York', 'NY', 'North Carolina', 'NC', 'North Dakota', 'ND', 'Northern Mariana Islands', 'MP', \n",
    "          'Ohio', 'OH', 'Oklahoma', 'OK', 'Oregon', 'OR', 'Palau', 'PW', 'Pennsylvania', 'PA', 'Puerto Rico', 'PR', \n",
    "          'Rhode Island', 'RI', 'South Carolina', 'SC', 'South Dakota', 'SD', 'Tennessee', 'TN', 'Texas', 'TX', \n",
    "          'Utah', 'UT', 'Vermont', 'VT', 'Virgin Islands', 'VI', 'Virginia', 'VA', 'Washington', 'WA', \n",
    "          'West Virginia', 'WV', 'Wisconsin', 'WI', 'Wyoming', 'WY']\n",
    "\n",
    "# Create dictionary for us_states with full name as key and abbreviation as value\n",
    "\n",
    "states_dict = {}\n",
    "for i in range(0, len(us_states)-1, 2):\n",
    "    states_dict[us_states[i]] = us_states[i+1]\n",
    "\n",
    "states_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf3799c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select only US locations from tweets\n",
    "\n",
    "is_in_US= []\n",
    "location_df = df['user_location'].fillna('')\n",
    "\n",
    "for location in location_df:\n",
    "    for state in us_states:\n",
    "        if state in location:\n",
    "            is_in_US.append(states_dict[state] if state in states_dict else state)\n",
    "\n",
    "location_df = pd.DataFrame(is_in_US)\n",
    "location_df = location_df.value_counts().rename_axis('State').reset_index(name='Counts')\n",
    "\n",
    "# Preview locations\n",
    "location_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea097ba8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create detailed vizualization\n",
    "# - line chart for minute by minute sentiment tracker\n",
    "# - bar plot for most frequent words\n",
    "# - choropleth map for total tweets per US state\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            specs=[[{\"type\": \"scatter\", \"colspan\": 2}, None],\n",
    "                  [{\"type\": \"bar\"}, {\"type\": \"choropleth\"}]],\n",
    "            subplot_titles=(\"\", \"Most frequent words\", \"Number of tweets per state\")\n",
    "    )\n",
    "\n",
    "fig.add_trace(go.Scatter(x=time_series, y=negative_polarity, mode='lines+markers', name='negative'), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=time_series, y=neutral_polarity, mode='lines+markers', name='neutral'), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=time_series, y=positive_polarity, mode='lines+markers', name='positive'), row=1, col=1)\n",
    "\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=top_words[\"Word\"], \n",
    "    y=top_words[\"Frequency\"], \n",
    "    name=\"Frequency\", \n",
    "    orientation='v'), row=2, col=1)\n",
    "\n",
    "fig.add_trace(go.Choropleth(\n",
    "    locations=location_df['State'], # Spatial coordinates\n",
    "    z = location_df['Counts'], # Data to be color-coded\n",
    "    locationmode = 'USA-states', # set of locations match entries in `locations`\n",
    "    colorscale = 'Reds',\n",
    "    colorbar_title = \"Count\",\n",
    "    name=''\n",
    "    \n",
    "))\n",
    "\n",
    "fig.update_layout(title={'text': 'Real Time Tweets Sentiment Tracker',\n",
    "                        'y':0.9,\n",
    "                        'x':0.5,\n",
    "                        'xanchor': 'center',\n",
    "                        'yanchor': 'top'},\n",
    "                 xaxis_title='Time', yaxis_title='Number of mentions',\n",
    "                 geo_scope='usa', \n",
    "                 height=800, width=1000)\n",
    "\n",
    "fig.data[-1].colorbar.x=1\n",
    "fig.data[-1].colorbar.y=.2\n",
    "fig.data[-1].colorbar.len=.5\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
